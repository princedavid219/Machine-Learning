{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S_kjO0xQ94nV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLsg6FstSD_6"
      },
      "source": [
        "# Importing the fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xDrqlCAu99fG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586a3fca-c234-4297-c80c-a35aa9268869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WTuWISNSDLf"
      },
      "source": [
        "# Splitting the Train dataset into Train and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2xq_2cCWQ6Tl"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full,\n",
        "                                                      test_size=5000)\n",
        "\n",
        "\n",
        "# Normalization\n",
        "X_train = X_train / 255.0\n",
        "X_valid = X_valid /255.0\n",
        "X_test = X_test / 255.0 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2OsaZtMZIzg"
      },
      "source": [
        "# Model - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY4e-x2V-o8s",
        "outputId": "22d0fff9-b44b-44e6-bf31-adb3ca722346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 28, 30)       870         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 28, 30)      120         ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 28, 60)       1860        ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 28, 60)      240         ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 28, 88)       0           ['input_1[0][0]',                \n",
            "                                                                  'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2464)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2464)         0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 10)           24650       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 27,740\n",
            "Trainable params: 27,560\n",
            "Non-trainable params: 180\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden_1 = keras.layers.Dense(30, activation='relu')(input)\n",
        "batch_1 = keras.layers.BatchNormalization()(hidden_1)\n",
        "hidden_2 = keras.layers.Dense(60, activation='relu')(batch_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(hidden_2)\n",
        "concat = keras.layers.Concatenate()([input, batch_2])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.3)(flatten)\n",
        "output = keras.layers.Dense(10, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OJ4hKCy-ypc",
        "outputId": "567556ac-c454-421e-94e3-3af32aad5072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1719/1719 [==============================] - 11s 5ms/step - loss: 0.5094 - accuracy: 0.8267 - val_loss: 0.4059 - val_accuracy: 0.8606\n",
            "Epoch 2/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3904 - accuracy: 0.8614 - val_loss: 0.3647 - val_accuracy: 0.8712\n",
            "Epoch 3/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3630 - accuracy: 0.8715 - val_loss: 0.3564 - val_accuracy: 0.8806\n",
            "Epoch 4/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3406 - accuracy: 0.8783 - val_loss: 0.3680 - val_accuracy: 0.8790\n",
            "Epoch 5/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3297 - accuracy: 0.8800 - val_loss: 0.3560 - val_accuracy: 0.8772\n",
            "Epoch 6/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3146 - accuracy: 0.8853 - val_loss: 0.3534 - val_accuracy: 0.8790\n",
            "Epoch 7/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3098 - accuracy: 0.8872 - val_loss: 0.3524 - val_accuracy: 0.8776\n",
            "Epoch 8/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3048 - accuracy: 0.8879 - val_loss: 0.3569 - val_accuracy: 0.8866\n",
            "Epoch 9/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2967 - accuracy: 0.8912 - val_loss: 0.3329 - val_accuracy: 0.8880\n",
            "Epoch 10/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2946 - accuracy: 0.8930 - val_loss: 0.3262 - val_accuracy: 0.8886\n",
            "Epoch 11/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2894 - accuracy: 0.8944 - val_loss: 0.3237 - val_accuracy: 0.8898\n",
            "Epoch 12/15\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2855 - accuracy: 0.8943 - val_loss: 0.3259 - val_accuracy: 0.8914\n",
            "Epoch 13/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2846 - accuracy: 0.8952 - val_loss: 0.3447 - val_accuracy: 0.8856\n",
            "Epoch 14/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2786 - accuracy: 0.8983 - val_loss: 0.3467 - val_accuracy: 0.8852\n",
            "Epoch 15/15\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2747 - accuracy: 0.8985 - val_loss: 0.3429 - val_accuracy: 0.8856\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=15,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAmeSb8WBOS0",
        "outputId": "28573522-23e2-4c94-e3f7-b399d51cabe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Acc:  89.85272645950317\n",
            "Validation Acc:  88.55999708175659\n",
            "Test Acc:  88.20000290870667\n"
          ]
        }
      ],
      "source": [
        "_, testaccuracy_1 = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", testaccuracy_1 * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCzr1Z71B1Dg"
      },
      "source": [
        "# Model - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovE6P_TLB0qO",
        "outputId": "07d1df83-f3f0-4c8a-c2b4-ee326468d0a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 28, 80)       2320        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 28, 80)      320         ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 28, 96)       7776        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 28, 96)      384         ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 28, 124)      0           ['input_2[0][0]',                \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 3472)         0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 3472)         0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 10)           34730       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,530\n",
            "Trainable params: 45,178\n",
            "Non-trainable params: 352\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden_1 = keras.layers.Dense(80, activation='relu')(input)\n",
        "batch_1 = keras.layers.BatchNormalization()(hidden_1)\n",
        "hidden_2 = keras.layers.Dense(96, activation='relu')(batch_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(hidden_2)\n",
        "concat = keras.layers.Concatenate()([input, batch_2])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.3)(flatten)\n",
        "output = keras.layers.Dense(10, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSxtqlhxC12i",
        "outputId": "e8f2d70a-1f2e-4617-b2b0-59733cdd622f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1719/1719 [==============================] - 10s 5ms/step - loss: 0.5105 - accuracy: 0.8304 - val_loss: 0.4694 - val_accuracy: 0.8368\n",
            "Epoch 2/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3915 - accuracy: 0.8646 - val_loss: 0.3747 - val_accuracy: 0.8764\n",
            "Epoch 3/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3541 - accuracy: 0.8747 - val_loss: 0.3783 - val_accuracy: 0.8702\n",
            "Epoch 4/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3321 - accuracy: 0.8812 - val_loss: 0.3428 - val_accuracy: 0.8822\n",
            "Epoch 5/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3145 - accuracy: 0.8867 - val_loss: 0.3373 - val_accuracy: 0.8872\n",
            "Epoch 6/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2966 - accuracy: 0.8926 - val_loss: 0.3564 - val_accuracy: 0.8806\n",
            "Epoch 7/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2871 - accuracy: 0.8953 - val_loss: 0.3453 - val_accuracy: 0.8844\n",
            "Epoch 8/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2784 - accuracy: 0.8989 - val_loss: 0.3327 - val_accuracy: 0.8840\n",
            "Epoch 9/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2709 - accuracy: 0.9020 - val_loss: 0.3451 - val_accuracy: 0.8864\n",
            "Epoch 10/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2622 - accuracy: 0.9039 - val_loss: 0.3283 - val_accuracy: 0.8948\n",
            "Epoch 11/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2564 - accuracy: 0.9062 - val_loss: 0.3499 - val_accuracy: 0.8840\n",
            "Epoch 12/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2530 - accuracy: 0.9072 - val_loss: 0.3801 - val_accuracy: 0.8686\n",
            "Epoch 13/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2498 - accuracy: 0.9078 - val_loss: 0.3320 - val_accuracy: 0.8896\n",
            "Epoch 14/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2437 - accuracy: 0.9091 - val_loss: 0.3762 - val_accuracy: 0.8764\n",
            "Epoch 15/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2365 - accuracy: 0.9122 - val_loss: 0.3308 - val_accuracy: 0.8950\n",
            "Epoch 16/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2373 - accuracy: 0.9126 - val_loss: 0.3322 - val_accuracy: 0.8952\n",
            "Epoch 17/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2316 - accuracy: 0.9143 - val_loss: 0.3350 - val_accuracy: 0.8924\n",
            "Epoch 18/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2304 - accuracy: 0.9137 - val_loss: 0.3260 - val_accuracy: 0.8958\n",
            "Epoch 19/20\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2238 - accuracy: 0.9162 - val_loss: 0.3359 - val_accuracy: 0.8896\n",
            "Epoch 20/20\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2247 - accuracy: 0.9168 - val_loss: 0.3465 - val_accuracy: 0.8894\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFQdhLVHC2mc",
        "outputId": "8ff924f3-6f4d-47d4-81f5-47e70da17ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Acc:  91.68363809585571\n",
            "Validation Acc:  88.94000053405762\n",
            "Test Acc:  88.63000273704529\n"
          ]
        }
      ],
      "source": [
        "_, testaccuracy_2 = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", testaccuracy_2 * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeIujOUoC8Z1"
      },
      "source": [
        "# Model - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW3OllAgC6IG",
        "outputId": "a694ab0d-ef84-4146-8c52-21987d99c16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 28, 80)       2320        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 28, 80)      320         ['dense_6[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 28, 240)      19440       ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 28, 240)     960         ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 28, 500)      120500      ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 28, 500)     2000        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 28, 528)      0           ['input_3[0][0]',                \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 14784)        0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 14784)        0           ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 10)           147850      ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 293,390\n",
            "Trainable params: 291,750\n",
            "Non-trainable params: 1,640\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden_1 = keras.layers.Dense(80, activation='relu')(input)\n",
        "batch_1 = keras.layers.BatchNormalization()(hidden_1)\n",
        "hidden_2 = keras.layers.Dense(240, activation='relu')(batch_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(hidden_2)\n",
        "hidden_3 = keras.layers.Dense(500, activation='relu')(batch_2)\n",
        "batch_3 = keras.layers.BatchNormalization()(hidden_3)\n",
        "concat = keras.layers.Concatenate()([input, batch_3])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.3)(flatten)\n",
        "output = keras.layers.Dense(10, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpZ1CiD5DSvM",
        "outputId": "6fe57f33-eb6d-43d9-c264-a482561dcfce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 12s 6ms/step - loss: 0.8610 - accuracy: 0.8171 - val_loss: 0.5287 - val_accuracy: 0.8514\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.5568 - accuracy: 0.8566 - val_loss: 0.4774 - val_accuracy: 0.8642\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4605 - accuracy: 0.8702 - val_loss: 0.4282 - val_accuracy: 0.8634\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3939 - accuracy: 0.8806 - val_loss: 0.4106 - val_accuracy: 0.8782\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3552 - accuracy: 0.8884 - val_loss: 0.4313 - val_accuracy: 0.8700\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3224 - accuracy: 0.8945 - val_loss: 0.3792 - val_accuracy: 0.8866\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2910 - accuracy: 0.9003 - val_loss: 0.3564 - val_accuracy: 0.8876\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2696 - accuracy: 0.9066 - val_loss: 0.3808 - val_accuracy: 0.8834\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2522 - accuracy: 0.9117 - val_loss: 0.3608 - val_accuracy: 0.8850\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2369 - accuracy: 0.9149 - val_loss: 0.3558 - val_accuracy: 0.8910\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2204 - accuracy: 0.9207 - val_loss: 0.3604 - val_accuracy: 0.8842\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2092 - accuracy: 0.9230 - val_loss: 0.3985 - val_accuracy: 0.8848\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2003 - accuracy: 0.9274 - val_loss: 0.4091 - val_accuracy: 0.8762\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1889 - accuracy: 0.9318 - val_loss: 0.3763 - val_accuracy: 0.8926\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1810 - accuracy: 0.9339 - val_loss: 0.3945 - val_accuracy: 0.8846\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1710 - accuracy: 0.9376 - val_loss: 0.4282 - val_accuracy: 0.8856\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1663 - accuracy: 0.9412 - val_loss: 0.4239 - val_accuracy: 0.8874\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1621 - accuracy: 0.9430 - val_loss: 0.4595 - val_accuracy: 0.8818\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1567 - accuracy: 0.9437 - val_loss: 0.4423 - val_accuracy: 0.8902\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1482 - accuracy: 0.9468 - val_loss: 0.4122 - val_accuracy: 0.8902\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1411 - accuracy: 0.9489 - val_loss: 0.4599 - val_accuracy: 0.8896\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1371 - accuracy: 0.9507 - val_loss: 0.4555 - val_accuracy: 0.8896\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1326 - accuracy: 0.9520 - val_loss: 0.4874 - val_accuracy: 0.8790\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1296 - accuracy: 0.9534 - val_loss: 0.5405 - val_accuracy: 0.8862\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1248 - accuracy: 0.9556 - val_loss: 0.5248 - val_accuracy: 0.8828\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=25,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hbssgXtDU2g",
        "outputId": "cf4d15f0-3d92-4840-c1e9-29fc6affd9d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Acc:  95.55636644363403\n",
            "Validation Acc:  88.27999830245972\n",
            "Test Acc:  88.84000182151794\n"
          ]
        }
      ],
      "source": [
        "_, testaccuracy_3 = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", testaccuracy_3 * 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg = (testaccuracy_1 + testaccuracy_2 + testaccuracy_3)/3\n",
        "print(avg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BqPmOoLHE6e",
        "outputId": "5abeae17-5eb5-41c6-9fbb-3e827953ea52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8855666915575663\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}